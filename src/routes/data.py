from fastapi import FastAPI, APIRouter, Depends, UploadFile, status, Request
from fastapi.responses import JSONResponse
import os
from helpers.config import get_settings, Settings
from controllers import DataController, ProjectController, ProcessController
from .schemas import ProcessRequest

from models import Asset
from models import ProjectModel, ChunkModel
from models import ResponseSignal
from models.AssetModel import AssetModel
from models import AssetTypeEnum
from models import DataChunkSchema

import aiofiles
import logging

logger = logging.getLogger('uvicorn.error')
data_router = APIRouter(
    prefix="/api/v1/data",
    tags=["api_v1_data", "data"]
)

@data_router.post("/upload/{project_id}")
async def upload_data(requset: Request, project_id: str, file: UploadFile,
                app_settings: Settings = Depends(get_settings)):

    project_model = await ProjectModel.create_instance(db_client=requset.app.db_client)
    print(f"Project Model Initialized: {project_model}")

    project = await project_model.get_project_or_create_one(project_id=project_id)
    print(f"Project Retrieved or Created: {project}")

    data_controller = DataController()
    is_valid, result_signal = data_controller.validate_uploaded_file(file)
    print(f"File Validation Result - is_valid: {is_valid}, signal: {result_signal}")

    if not is_valid:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
                content = {
                "signal": result_signal
            }
        )

    project_dir_path = ProjectController().get_project_path(project_id=project_id)
    file_path, file_id = data_controller.generate_unique_filepath(
        org_file_name=file.filename,
        project_id=project_id
    )
    
    try:
        async with aiofiles.open(file_path, "wb") as f:
            while chunk := await file.read(app_settings.FILE_DEFAULT_CHUNK_SIZE):
                await f.write(chunk)
    except Exception as e:
             logger.error(f"Error while uploading file: {e}")

             return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
                content = {
                "signal": ResponseSignal.FILE_UPLOAD_FAILED.value
            }
        )
    # store the assets in the database
    asset_model = await AssetModel.create_instance(db_client=requset.app.db_client)
    asset_record = Asset(
        asset_project_id= project.id,
        asset_type=AssetTypeEnum.FILE.value,
        asset_name=file_id,
        asset_size=os.path.getsize(file_path)
        )
    asset_record = await asset_model.create_asset(asset=asset_record)


    return JSONResponse(
        status_code=status.HTTP_200_OK,
        content={
            "signal": ResponseSignal.FILE_UPLOAD_SUCESS.value,
            "file_id": str(asset_record.id),
        },
    )
    
@data_router.post("/process/{project_id}")
async def process_endpoint(request: Request,project_id: str, process_request: ProcessRequest):
    file_id = process_request.file_id
    chunk_size = process_request.chunk_size
    overlap_size = process_request.overlap_size

    project_model = await ProjectModel.create_instance(db_client=request.app.db_client)
    chunk_model = await ChunkModel.create_instance(db_client=request.app.db_client)

    project = await project_model.get_project_or_create_one(project_id=project_id)
    process_controller = ProcessController(project_id=project_id)
    
    file_content = process_controller.get_file_content(file_id=file_id)

    if file_content is None or len(file_content) == 0 or all(len(rec.page_content.strip()) == 0 for rec in file_content):
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"signal": ResponseSignal.NO_TEXT_IN_FILE.value}
        )

    file_chunks = process_controller.process_file_content(file_content=file_content,
                                                            file_id=file_id,
                                                            chunk_size=chunk_size,
                                                            chunk_overlap=overlap_size)

    if file_chunks is None or len(file_chunks) == 0:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
                content = {
                "signal": ResponseSignal.PROCESSING_FAILED.value
            }
        )

    file_chunks_records = [
         DataChunkSchema(
            chunk_text=chunk.page_content,
            chunk_metadata=chunk.metadata,
            chunk_order=i + 1,
            chunk_project_id=project.id)
         for i, chunk in enumerate(file_chunks)
    ]

    if process_request.do_reset ==1:
        deleted_chunks = await chunk_model.delete_chunks_by_project_id(project_id=project.id)
        print("++++++++++++++++++++++++++++")
        print(f"Deleted {deleted_chunks} existing chunks for project_id: {project_id}")

    numbers_of_inserted_chunks = await chunk_model.insert_many_chunks(chunks=file_chunks_records)

    if numbers_of_inserted_chunks == 0:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
                content = {
                "signal": ResponseSignal.PROCESSING_FAILED.value
            }
        )
    return JSONResponse(
        status_code=status.HTTP_200_OK,
        content={
            "signal": ResponseSignal.PROCESSING_SUCESS.value,
            "number_of_chunks": numbers_of_inserted_chunks,
        },
    )
